{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Adding products to your localhost postgres database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "\thost=\"localhost\",\n",
    "\tdatabase=\"hackonwithamazon\",\n",
    "\tuser=os.getenv(\"USER\"),\n",
    "\tpassword=os.getenv(\"PASSWORD\")\n",
    ")\n",
    "try:\n",
    "\tcurs = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)\n",
    "\n",
    "\tcurs.execute(\"CREATE TABLE products(id INTEGER PRIMARY KEY, img VARCHAR(30), price REAL, title VARCHAR(50), rating REAL)\")\n",
    "\n",
    "\tcurs.execute(\"INSERT INTO products VALUES(1, '1.jpeg', 24.65, 'Men Polyester Green T-Shirt', 4.1)\")\n",
    "\tcurs.execute(\"INSERT INTO products VALUES(2, '2.jpeg', 27.89, 'Cool Cargo Material Men Pant', 4.3)\")\n",
    "\tcurs.execute(\"INSERT INTO products VALUES(3, '3.jpeg', 18.25, 'Green Long Fit Pant', 4.6)\")\n",
    "\tcurs.execute(\"INSERT INTO products VALUES(4, '4.jpeg', 12.99, 'Comfortable Men Cargo Pant', 3.9)\")\n",
    "\tcurs.execute(\"INSERT INTO products VALUES(5, '5.jpeg', 30, 'Cargo Dark Green Pant', 4.3)\")\n",
    "\tcurs.execute(\"INSERT INTO products VALUES(6, '6.jpeg', 17.35, 'Green Men Cargo Pant', 4.1)\")\n",
    "\tcurs.execute(\"INSERT INTO products VALUES(7, '7.jpeg', 20.87, 'Navy Blue Men Pant', 4)\")\n",
    "\tcurs.execute(\"INSERT INTO products VALUES(8, '8.jpeg', 31.5, 'Women Full White Pant', 3.8)\")\n",
    "\tcurs.execute(\"INSERT INTO products VALUES(9, '9.jpeg', 29.65, 'Awesome Woolen Men Shirts', 4.5)\")\n",
    "\tcurs.execute(\"INSERT INTO products VALUES(10, '10.jpeg', 25.87, 'Super Cool Red Men Shirt', 4.2)\")\n",
    "\tcurs.execute(\"INSERT INTO products VALUES(11, '11.jpeg', 15.4, 'Pure White Shirt For Men', 4.3)\")\n",
    "\tcurs.execute(\"INSERT INTO products VALUES(12, '12.jpeg', 18.35, 'White Fullhand Men Shirt', 4.2)\")\n",
    "\tcurs.execute(\"INSERT INTO products VALUES(13, '13.jpeg', 24.20, 'Cool Modern White Shirt', 3.4)\")\n",
    "\tcurs.execute(\"INSERT INTO products VALUES(14, '14.jpeg', 26.80, 'Dark Blue Jacket', 3.9)\")\n",
    "\tcurs.execute(\"INSERT INTO products VALUES(15, '15.jpeg', 21.45, 'Pretty Blue Men Jacket', 4.5)\")\n",
    "\tcurs.execute(\"INSERT INTO products VALUES(16, '16.jpeg', 8.25, 'Military Cap', 4.1)\")\n",
    "\tcurs.execute(\"INSERT INTO products VALUES(17, '17.jpeg', 10, 'Small Military Cap', 4.7)\")\n",
    "\tcurs.execute(\"INSERT INTO products VALUES(18, '18.jpeg', 16.50, 'Green T-shirt', 4.0)\")\n",
    "\tcurs.execute(\"INSERT INTO products VALUES(19, '19.jpeg', 30.25, 'Pair of Green Tshirts', 3.4)\")\n",
    "\tcurs.execute(\"INSERT INTO products VALUES(20, '20.jpeg', 25, 'Floral Printed Dress', 4.3)\")\n",
    "\n",
    "\tcurs.close()\n",
    "finally:\n",
    "\tconn.commit()\n",
    "\tconn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating pickle files for feature vectors and corresponding database ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from dotenv import load_dotenv\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('similar_search/resnet50_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(image, model):\n",
    "    image = image.resize((224, 224))\n",
    "    image = np.array(image)\n",
    "    pre_img = preprocess_input(np.expand_dims(image, axis=0))\n",
    "    result = model.predict(pre_img).flatten()\n",
    "    normalized = result / norm(result)\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"hackonwithamazon\",\n",
    "    user=os.getenv(\"USER\"),\n",
    "    password=os.getenv(\"PASSWORD\")\n",
    ")\n",
    "\n",
    "feature_vectors = []\n",
    "db_ids = []\n",
    "\n",
    "try:\n",
    "\tcurs = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)\n",
    "\n",
    "\tcurs.execute(\"SELECT id, img FROM products\")\n",
    "\tresults = curs.fetchall()\n",
    "\tfor row in results:\n",
    "\t\tdb_ids.append(row[\"id\"])\n",
    "\t\timage = Image.open(\"database-imgs/\"+row[\"img\"])\n",
    "\t\tfeature_vectors.append(feature_extraction(image, model))\n",
    "\t\n",
    "\tcurs.close()\n",
    "finally:\n",
    "\tconn.commit()\n",
    "\tconn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(feature_vectors, open('similar_search/feature_vectors.pkl', 'wb'))\n",
    "pickle.dump(db_ids, open('similar_search/db_ids.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
